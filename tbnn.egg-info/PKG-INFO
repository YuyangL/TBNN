Metadata-Version: 1.2
Name: tbnn
Version: 1.0b0
Summary: A Tensor-Basis Neural Network Trainer
Home-page: http://www.github.com/tbnn
Author: Julia Ling
Author-email: jling@sandia.gov
Maintainer: Jeremy Templeton
Maintainer-email: jatempl@sandia.gov
License: UNKNOWN
Description: # Tensor Basis Neural Network
        
        The Tensor Basis Neural Network (TBNN) package provides an interface for building, training, and
        testing neural networks for systems that have known invariance properties.  This package is intended
        as a useful reference and starting point for researchers hoping to develop data-driven constitutive models
        for systems with known invariance properties.
        
        ## Copyright and License
        
        Copyright 2017 Sandia Corporation. Under the terms of Contract DE-AC04-94AL85000 with Sandia Corporation, the U.S. Government retains certain rights in this software.  It is distributed under the BSD-3-Clause license.
        
        ## Reference:
        
        Ling, Julia, Andrew Kurzawski, and Jeremy Templeton. "Reynolds averaged turbulence modelling using deep neural networks
        with embedded invariance." Journal of Fluid Mechanics 807 (2016): 155-166.
        
        ## Background Theory:
        
        In many physical systems, there are known invariance properties.  For example, the equations of motion
        obey Galilean invariance, which means that they are invariant to inertial coordinate transformations.
        Many crystals obey crystal symmetry constraints.  As we build machine learning models for these systems,
        it has been demonstrated that we can achieve better accuracy at lower computational cost by directly embedding
        these constraints.
        
        The TBNN architecture enables the direct embedding of tensor invariance properties into the neural network
        architecture.  The TBNN architecture is based on concepts from representation theory and tensor invariance
        theory.
        
        Lets say that we want to build a model where the inputs are tensors A and B and vector v and the output is
        a tensor Y.  Furthermore, we know that Y obeys a known invariance constraint.  This can be expressed as:
        
        if Y = Y(A, B, v)
        
        then Y(Q A Q^T, Q B Q^T, Q v) = Q Y(A, B, v) Q^T
        
        
        In this notation, Q is any matrix from the specified invariance group.  Q^T is the transpose of Q.  The
        basic idea is that if the inputs are transformed by some matrix from the invariance group, then the output
        should be transformed correspondingly.
        
        For an arbitrary set of vectors and tensors and a specified invariance condition, it is possible to
        construct a finite tensor basis (S<sub>1</sub>, S<sub>2</sub>, ..., S<sub>n</sub>) and a finite scalar basis (c<sub>1</sub>, c<sub>2</sub>, ..., c<sub>m</sub>).  
        We can then say that any function of those
        vectors and tensors should sit on the tensor basis:
        
        Y = sum<sub>i</sub> [f<sub>i</sub>(c<sub>1</sub>, ..., c<sub>m</sub>) S<sub>i</sub> ]
        
        In other words, our output Y can be expressed as a linear combination of the tensor basis, where the coefficients are
        given by unknown functions f_i of the scalar invariants.  The tensor basis can either be calculated afresh or
        can often be looked up in the literature, where many such bases have been tabulated.
        
        The Tensor Basis Neural Network uses this concept to ensure that the model obeys the specified invariance constraints.
        It has two input layers.  The first input layer accepts the scalar invariant basis.  These inputs are then transformed
        through multiple densely connected hidden layers.  The second input layer accepts the tensor basis.  The final hidden
        layer is then pair-wise multiplied by this tensor basis input layer and summed to provide the output.  Thus,
        the TBNN directly maps the tensor basis equation into the neural network architecture.
        
        ## Copyright:
        Copyright 2017 Sandia Corporation. Under the terms of Contract DE-AC04-94AL85000, 
        there is a non-exclusive license for use of this work by or on behalf of the U.S. Government. 
        Export of this program may require a license from the United States Government.
        
        
Keywords: sandia neuralnetwork tensor
Platform: UNKNOWN
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Environment :: Console
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 2.6
Classifier: Programming Language :: Python :: 2.7
